{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "\n",
    "import model_V3 as Model\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clone GenSen repo here: https://github.com/Maluuba/gensen.git\n",
    "And follow instructions for loading the model used in batcher\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Loading Encoding Document\n",
    "\"\"\"\n",
    "\n",
    "print('build data')\n",
    "COMMON_VOCAB_FILE = 'words.txt'\n",
    "GERMAN_VOCAB_FILE = 'german_words.txt'\n",
    "TREE_VOCAB_FILE = 'tree_words.txt'\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    vocab = tf.contrib.lookup.index_table_from_file(COMMON_VOCAB_FILE, num_oov_buckets=1)\n",
    "    vocab_german = tf.contrib.lookup.index_table_from_file(GERMAN_VOCAB_FILE,num_oov_buckets=1)\n",
    "    vocab_tree  = tf.contrib.lookup.index_table_from_file(TREE_VOCAB_FILE,num_oov_buckets=1)\n",
    "    \n",
    "    model = Model.Model(30002,30002,76)   \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.002)\n",
    "    checkpoint_directory = '../../models_checkpoints/common/'\n",
    "    chkpnt = tf.contrib.eager.Checkpoint(optimizer=optimizer, model=model, optimizer_step=tf.train.get_or_create_global_step())\n",
    "    print(chkpnt.restore(tf.train.latest_checkpoint(checkpoint_directory)))\n",
    "    #log_msg(\"Restored Model upto Previous Checkpoint\")\n",
    "    \n",
    "    vocabs = {\n",
    "        \"English\" : vocab,\n",
    "        \"German \" : vocab_german,\n",
    "        \"Tree \":vocab_tree\n",
    "    }\n",
    "    return model, vocabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus object at 0x7fa160247a58>\n"
     ]
    }
   ],
   "source": [
    "model,vocabs = get_model()\n",
    "np.save('../data/Emb.npy',model.rnn.W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-12 05:59:12,149 : ***** Transfer task : MR *****\n",
      "\n",
      "\n",
      "2018-10-12 05:59:12,286 : Generating sentence embeddings\n",
      "2018-10-12 05:59:35,840 : Generated sentence embeddings\n",
      "2018-10-12 05:59:36,073 : ***** Transfer task : CR *****\n",
      "\n",
      "\n",
      "2018-10-12 05:59:36,091 : Generating sentence embeddings\n",
      "2018-10-12 05:59:44,056 : Generated sentence embeddings\n",
      "2018-10-12 05:59:44,077 : ***** Transfer task : MPQA *****\n",
      "\n",
      "\n",
      "2018-10-12 05:59:44,100 : Generating sentence embeddings\n",
      "2018-10-12 06:00:01,906 : Generated sentence embeddings\n",
      "2018-10-12 06:00:02,055 : ***** Transfer task : SUBJ *****\n",
      "\n",
      "\n",
      "2018-10-12 06:00:02,264 : Generating sentence embeddings\n",
      "2018-10-12 06:00:25,956 : Generated sentence embeddings\n",
      "2018-10-12 06:00:26,185 : ***** Transfer task : SST Binary classification *****\n",
      "\n",
      "\n",
      "2018-10-12 06:00:26,740 : Computing embedding for train\n",
      "2018-10-12 06:02:46,366 : Computed train embeddings\n",
      "2018-10-12 06:02:46,381 : Computing embedding for dev\n",
      "2018-10-12 06:02:48,840 : Computed dev embeddings\n",
      "2018-10-12 06:02:48,857 : Computing embedding for test\n",
      "2018-10-12 06:02:53,864 : Computed test embeddings\n",
      "2018-10-12 06:02:53,871 : ***** Transfer task : SST Fine-Grained classification *****\n",
      "\n",
      "\n",
      "2018-10-12 06:02:53,918 : Computing embedding for train\n",
      "2018-10-12 06:03:15,941 : Computed train embeddings\n",
      "2018-10-12 06:03:15,944 : Computing embedding for dev\n",
      "2018-10-12 06:03:19,088 : Computed dev embeddings\n",
      "2018-10-12 06:03:19,097 : Computing embedding for test\n",
      "2018-10-12 06:03:24,933 : Computed test embeddings\n",
      "2018-10-12 06:03:24,936 : ***** Transfer task : MRPC *****\n",
      "\n",
      "\n",
      "2018-10-12 06:03:24,977 : Computing embedding for train\n",
      "2018-10-12 06:03:48,234 : Computed train embeddings\n",
      "2018-10-12 06:03:48,235 : Computing embedding for test\n",
      "2018-10-12 06:03:57,940 : Computed test embeddings\n",
      "2018-10-12 06:03:57,948 : ***** Transfer task : SICK-Entailment*****\n",
      "\n",
      "\n",
      "2018-10-12 06:03:57,980 : Computing embedding for train\n",
      "2018-10-12 06:04:22,228 : Computed train embeddings\n",
      "2018-10-12 06:04:22,229 : Computing embedding for dev\n",
      "2018-10-12 06:04:24,909 : Computed dev embeddings\n",
      "2018-10-12 06:04:24,912 : Computing embedding for test\n",
      "2018-10-12 06:04:50,620 : Computed test embeddings\n",
      "2018-10-12 06:04:50,622 : ***** Transfer task : SICK-Relatedness*****\n",
      "\n",
      "\n",
      "2018-10-12 06:04:50,676 : Computing embedding for train\n",
      "2018-10-12 06:05:02,430 : Computed train embeddings\n",
      "2018-10-12 06:05:02,436 : Computing embedding for train\n",
      "2018-10-12 06:05:15,428 : Computed train embeddings\n",
      "2018-10-12 06:05:15,430 : Computing embedding for dev\n",
      "2018-10-12 06:05:16,887 : Computed dev embeddings\n",
      "2018-10-12 06:05:16,891 : Computing embedding for dev\n",
      "2018-10-12 06:05:18,727 : Computed dev embeddings\n",
      "2018-10-12 06:05:18,743 : Computing embedding for test\n",
      "2018-10-12 06:05:31,636 : Computed test embeddings\n",
      "2018-10-12 06:05:31,639 : Computing embedding for test\n",
      "2018-10-12 06:05:45,876 : Computed test embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Generating Data\n"
     ]
    }
   ],
   "source": [
    "# # Set PATHs\n",
    "\n",
    "PATH_TO_SENTEVAL = '../'\n",
    "PATH_TO_DATA = '../data'\n",
    "\n",
    "# import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "\n",
    "import senteval\n",
    "\n",
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return samples\n",
    "\n",
    "def encoder(*args):\n",
    "    pass\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = []\n",
    "    def process():\n",
    "        for sample in batch:\n",
    "            sentence = ' '.join(sample)\n",
    "            sentence = tf.convert_to_tensor(sentence,dtype=tf.string)\n",
    "            string = tf.string_split([sentence]).values\n",
    "            str_idx = vocabs[\"English\"].lookup(string)\n",
    "            len_string = tf.cast(tf.size(str_idx),dtype=tf.int64)\n",
    "            yield str_idx,len_string\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "      process, (tf.int64, tf.int64), (tf.TensorShape([None]), tf.TensorShape([])))\n",
    "    ds = ds.padded_batch(batch_size=256, padded_shapes=([None],[]),padding_values=\n",
    "                         (tf.convert_to_tensor(0,dtype=tf.int64),tf.convert_to_tensor(0,dtype=tf.int64)))\n",
    "    ds = iter(ds)\n",
    "    emb = []\n",
    "    for d in ds:\n",
    "        fs = model.rnn.frwrd(d[0],d[1],False)\n",
    "        emb.append(fs.numpy())\n",
    "    return np.vstack(emb)\n",
    "\n",
    "# Set params for SentEval\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': False}\n",
    "params_senteval['classifier'] = {}\n",
    "\n",
    "params_senteval['gensen'] = encoder\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks = [\n",
    "                      # 'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n",
    "                      # 'TREC', \n",
    "                      # 'STSBenchmark'\n",
    "                      'MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'SST5', \n",
    "                      'MRPC',\n",
    "                      'SICKEntailment', \n",
    "                      'SICKRelatedness'\n",
    "                      ]\n",
    "                      # 'Length', 'WordContent', 'Depth', 'TopConstituents',\n",
    "                      # 'BigramShift', 'Tense', 'SubjNumber', 'ObjNumber',\n",
    "                      # 'OddManOut', 'CoordinationInversion']\n",
    "    results = se.eval(transfer_tasks)\n",
    "    print('Completed Generating Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
